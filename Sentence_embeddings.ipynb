{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stance detection\n",
    "\n",
    "After reviewing the latest literature on the SemEval2016, I think it's a good starting point to formulate the problem into a text classification with sentence-pair inputs (keeping it simple!). However, I suggest using pre-trained language models to generate meaningful sentence embeddings, rather than training the model from scratch on the available data. \n",
    "\n",
    "The language models used are:<br>\n",
    "1- Google's BERT model [1]. Bidirectional Transformers for Language Understanding [2] is arguably the best pre-trained language model available; capable of achieving state-of-the-art results in various NLP tasks. \n",
    "\n",
    "2- Flair embeddings [3,4]. Contextual String Embeddings for Sequence Labeling is currently the state-of-the-art [4] system in Named Entity Recognition task, and the only system outperforming Google's BERT model in this application. \n",
    "\n",
    "Both models are expensive to use (especially on my potato laptop), however, using them improve my chances of achieving better results. I also wanted an excuse to play with them :)\n",
    "\n",
    "The suggested architecture looks like this..\n",
    "\n",
    "\n",
    "\n",
    "I experiment with three types of embeddings;<br>\n",
    "1- Flair's Document Pool Embeddings<br>\n",
    "2- Flair's Document LSTM Embeddings<br>\n",
    "3- Google's BERT Embeddings<br>\n",
    "\n",
    "At the end of this code, I suggest further improvements that can help improve the obtained results.\n",
    "\n",
    "Requirements to run this code:\n",
    "- python 3.6\n",
    "- bert\n",
    "- flair\n",
    "- pytorch\n",
    "- tensorflow\n",
    "\n",
    "[1] https://github.com/google-research/bert<br>\n",
    "[2] https://arxiv.org/abs/1810.04805<br>\n",
    "[3] https://github.com/zalandoresearch/flair<br>\n",
    "[4] https://drive.google.com/file/d/17yVpFA7MmXaQFTe-HDpZuqw9fJlmzg56/view<br>\n",
    "[5] https://github.com/zalandoresearch/flair#comparison-with-state-of-the-art<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initlaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading/Inspecting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has 2914 instances\n",
      "Hillary Clinton                     689\n",
      "Feminist Movement                   664\n",
      "Legalization of Abortion            653\n",
      "Atheism                             513\n",
      "Climate Change is a Real Concern    395\n",
      "Name: Target, dtype: int64 \n",
      "\n",
      "Test data has 1249 instances\n",
      "Hillary Clinton                     295\n",
      "Feminist Movement                   285\n",
      "Legalization of Abortion            280\n",
      "Atheism                             220\n",
      "Climate Change is a Real Concern    169\n",
      "Name: Target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def _check_dir(_dir):\n",
    "    output_dir = Path(_dir)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "\n",
    "# path to SemEval dataset\n",
    "dataset_path = 'Dataset/'\n",
    "\n",
    "# creating a dir for data and embeddings\n",
    "_check_dir('data')\n",
    "_check_dir('embeddings')\n",
    "\n",
    "#=------------------------------------------------=#\n",
    "## Training data\n",
    "Training_data = []\n",
    "\n",
    "with open(dataset_path + 'SemEval2016-Task6-subtaskA-traindata-gold.csv', 'r',  encoding=\"iso-8859-1\") as fin:\n",
    "    reader = csv.reader(fin, quotechar='\"')\n",
    "    columns = next(reader)\n",
    "    for line in reader:\n",
    "        Training_data.append(line)\n",
    "        \n",
    "train_df = pd.DataFrame(Training_data, columns=columns)\n",
    "classes = list( set(train_df['Stance']) )\n",
    "\n",
    "print('Training data has %d instances' %(len(Training_data,)))\n",
    "print(train_df['Target'].value_counts(), '\\n')\n",
    "\n",
    "#=------------------------------------------------=#\n",
    "## Test data\n",
    "Test_data = []\n",
    "\n",
    "with open(dataset_path + 'SemEval2016-Task6-subtaskA-testdata-gold.txt', 'r',  encoding=\"iso-8859-1\") as fin:\n",
    "    reader = csv.reader(fin, delimiter='\\t')\n",
    "    columns = next(reader)\n",
    "    for line in reader:\n",
    "        Test_data.append(line)\n",
    "\n",
    "test_df = pd.DataFrame(Test_data, columns=columns)\n",
    "\n",
    "print('Test data has %d instances' %(len(Test_data,)))\n",
    "print(test_df['Target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  *Training has ( 2619 ) instances.\n",
      "  *Validation has ( 295 ) instances.\n",
      "  *Test has ( 1249 ) instances.\n"
     ]
    }
   ],
   "source": [
    "##== prepare data for Flair ==##\n",
    "\n",
    "# creating a dir for data\n",
    "path_save_data = 'data/Flair'\n",
    "_check_dir(path_save_data)\n",
    "\n",
    "# reading training data\n",
    "Targets = train_df['Target'].values\n",
    "Tweets = train_df['Tweet'].values\n",
    "Stances = train_df['Stance'].values\n",
    "data = [[stance, target, tweet] for stance, target, tweet in zip(Stances, Targets, Tweets)]\n",
    "\n",
    "random.shuffle(data)    # shuffling the data is always good to preven overfitting\n",
    "\n",
    "# dividing the data into trainig (90%), validation (10%).\n",
    "split_ = int(0.1 * len(data))\n",
    "TRAIN_DATA, VAL_DATA = data[:9*split_], data[9*split_:]\n",
    "\n",
    "# reading testing data\n",
    "Targets = test_df['Target'].values\n",
    "Tweets = test_df['Tweet'].values\n",
    "Stances = test_df['Stance'].values\n",
    "TEST_DATA = [[stance, target, tweet] for stance, target, tweet in zip(Stances, Targets, Tweets)]\n",
    "\n",
    "# print the amount of data in each\n",
    "print('  *Training has (',len(TRAIN_DATA),') instances.')\n",
    "print('  *Validation has (',len(VAL_DATA),') instances.')\n",
    "print('  *Test has (',len(TEST_DATA),') instances.')\n",
    "\n",
    "# dump all data for future use\n",
    "for name, data in zip(['train','val','test'],[TRAIN_DATA, VAL_DATA, TEST_DATA]):\n",
    "    pickle.dump(data, open(path_save_data+'/'+name+'.p','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##== prepare data for BERT ==##\n",
    "\n",
    "# creating a dir for data\n",
    "path_save_data = 'data/BERT'\n",
    "_check_dir(path_save_data)\n",
    "\n",
    "# loop through data\n",
    "for name, data in zip(['train','val','test'],[TRAIN_DATA, VAL_DATA, TEST_DATA]):\n",
    "    File_ = open(path_save_data+'/'+name+'.txt','w')\n",
    "    for stance, target, tweet in data:\n",
    "        File_.write(target+' ||| '+tweet+'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting sentence embeddings (Flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, CharLMEmbeddings, DocumentPoolEmbeddings, DocumentLSTMEmbeddings\n",
    "from flair.data import Sentence, TaggedCorpus, Token\n",
    "\n",
    "# initialize the word embeddings\n",
    "# the -fast embeddings are CPU friendly\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "charlm_embedding_forward = CharLMEmbeddings('news-forward')\n",
    "charlm_embedding_backward = CharLMEmbeddings('news-backward')\n",
    "\n",
    "# initialize the document embeddings\n",
    "\n",
    "# Embedding(1)\n",
    "# glove = 100\n",
    "# charlm_embedding_backward = 1024\n",
    "# charlm_embedding_forward = 1024\n",
    "document_embeddings1 = DocumentPoolEmbeddings([glove_embedding,\n",
    "                                              charlm_embedding_backward,\n",
    "                                              charlm_embedding_forward])\n",
    "\n",
    "\n",
    "# Embedding(2)\n",
    "# a total of 128 vector generated by an LSTM\n",
    "document_embeddings2 = DocumentLSTMEmbeddings([glove_embedding,\n",
    "                                              charlm_embedding_backward,\n",
    "                                              charlm_embedding_forward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -processed:0 examples\n",
      "  -processed:100 examples\n",
      "  -processed:200 examples\n",
      "  -processed:300 examples\n",
      "  -processed:400 examples\n",
      "  -processed:500 examples\n",
      "  -processed:600 examples\n",
      "  -processed:700 examples\n",
      "  -processed:800 examples\n",
      "  -processed:900 examples\n",
      "  -processed:1000 examples\n",
      "  -processed:1100 examples\n",
      "  -processed:1200 examples\n",
      "  -processed:1300 examples\n",
      "  -processed:1400 examples\n",
      "  -processed:1500 examples\n",
      "  -processed:1600 examples\n",
      "  -processed:1700 examples\n",
      "  -processed:1800 examples\n",
      "  -processed:1900 examples\n",
      "  -processed:2000 examples\n",
      "  -processed:2100 examples\n",
      "  -processed:2200 examples\n",
      "  -processed:2300 examples\n",
      "  -processed:2400 examples\n",
      "  -processed:2500 examples\n",
      "  -processed:2600 examples\n",
      "  -processed:0 examples\n",
      "  -processed:100 examples\n",
      "  -processed:200 examples\n",
      "  -processed:0 examples\n",
      "  -processed:100 examples\n",
      "  -processed:200 examples\n",
      "  -processed:300 examples\n",
      "  -processed:400 examples\n",
      "  -processed:500 examples\n",
      "  -processed:600 examples\n",
      "  -processed:700 examples\n",
      "  -processed:800 examples\n",
      "  -processed:900 examples\n",
      "  -processed:1000 examples\n",
      "  -processed:1100 examples\n",
      "  -processed:1200 examples\n"
     ]
    }
   ],
   "source": [
    "path_save_embd = 'embeddings/Flair'\n",
    "path_save_data = 'data/Flair'\n",
    "\n",
    "_check_dir(path_save_embd)\n",
    "\n",
    "try:\n",
    "    TRAIN_DATA = pickle.load(open(path_save_data+'/train.p','rb'))\n",
    "    VAL_DATA = pickle.load(open(path_save_data+'/val.p','rb'))\n",
    "    TEST_DATA = pickle.load(open(path_save_data+'/test.p','rb'))\n",
    "except:\n",
    "    TRAIN_DATA, VAL_DATA, TEST_DATA = [],[],[]\n",
    "    print('Please check your directories..')\n",
    "    \n",
    "def _get_embeddings(length, data):\n",
    "    Y = torch.zeros([length,3])\n",
    "    X1 = torch.zeros([length,8392]) # Pool Embeddings\n",
    "    X2 = torch.zeros([length,256])  # LSTM Embeddings\n",
    "    \n",
    "    X_target = {} ## store the target embeddings to prevent recalucalting them each time\n",
    "\n",
    "    for counter, data in enumerate(data[:length]):\n",
    "        stance, target, tweet = data\n",
    "        if np.mod(counter,100)==0:\n",
    "            print('  -processed:%d examples' %(counter))\n",
    "\n",
    "        Y[counter,classes.index(stance)] = 1\n",
    "\n",
    "        # create an example sentence\n",
    "        if target not in X_target:\n",
    "            sentence1_1 = Sentence(target)\n",
    "            sentence1_2 = Sentence(target)\n",
    "            \n",
    "            document_embeddings1.embed(sentence1_1)\n",
    "            document_embeddings2.embed(sentence1_2)\n",
    "            \n",
    "            embd_T1 = sentence1_1.get_embedding()[0]\n",
    "            embd_T2 = sentence1_2.get_embedding()[0]\n",
    "            \n",
    "            X_target[target] = [embd_T1, embd_T2]\n",
    "        else:\n",
    "            embd_T1, embd_T2 = X_target[target]\n",
    "        \n",
    "        \n",
    "        # create an example sentence\n",
    "        # embed the sentence with our document embedding\n",
    "        sentence2_1 = Sentence(tweet)\n",
    "        sentence2_2 = Sentence(tweet)\n",
    "        \n",
    "        document_embeddings1.embed(sentence2_1)\n",
    "        document_embeddings2.embed(sentence2_2)\n",
    "        \n",
    "        embd1 = sentence2_1.get_embedding()[0]\n",
    "        embd2 = sentence2_2.get_embedding()[0]\n",
    "        \n",
    "        X1[counter,:] = torch.cat((embd_T1, embd1), 0).data\n",
    "        X2[counter,:] = torch.cat((embd_T2, embd2), 0).data\n",
    "    return [X1,X2,Y]\n",
    "\n",
    "TRAIN_EMBD = _get_embeddings(len(TRAIN_DATA), TRAIN_DATA)\n",
    "VAL_EMBD = _get_embeddings(len(VAL_DATA), VAL_DATA)\n",
    "TEST_EMBD = _get_embeddings(len(TEST_DATA), TEST_DATA)\n",
    "\n",
    "pickle.dump(TRAIN_EMBD, open(path_save_embd+'/train_embd.p', 'wb'))\n",
    "pickle.dump(VAL_EMBD, open(path_save_embd+'/val_embd.p', 'wb'))\n",
    "pickle.dump(TEST_EMBD, open(path_save_embd+'/test_embd.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Sentence Embeddings (BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 0\n",
      "INFO:tensorflow:tokens: [CLS] hillary clinton [SEP] another # hillary supporter committed to caucus tonight ! one more step on the way to winning the iowa caucus . # se ##ms ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 18520 7207 102 2178 1001 18520 10129 5462 2000 13965 3892 999 2028 2062 3357 2006 1996 2126 2000 3045 1996 5947 13965 1012 1001 7367 5244 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_type_ids: 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 1\n",
      "INFO:tensorflow:tokens: [CLS] feminist movement [SEP] at the w ##gs ##s discussion forum at # ala ##ac ##15 . love these librarian ##s ! # fuck ##ye ##ahl ##ib ##rar ##ians # se ##ms ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 10469 2929 102 2012 1996 1059 5620 2015 6594 7057 2012 1001 21862 6305 16068 1012 2293 2122 13850 2015 999 1001 6616 6672 28083 12322 19848 7066 1001 7367 5244 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_type_ids: 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 2\n",
      "INFO:tensorflow:tokens: [CLS] hillary clinton [SEP] @ time ##no ##ut is there anything about the clinton ##s that is not fraudulent ? # se ##ms ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 18520 7207 102 1030 2051 3630 4904 2003 2045 2505 2055 1996 7207 2015 2008 2003 2025 27105 1029 1001 7367 5244 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_type_ids: 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 3\n",
      "INFO:tensorflow:tokens: [CLS] legal ##ization of abortion [SEP] dear nuns , your advocacy of tax paying is weird . # war # iraq # death ##pen ##al ##ty # taxes ##pa ##y ##forth ##isto ##o # taxpayer ##pr ##ide # se ##ms ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 3423 3989 1997 11324 102 6203 16752 1010 2115 12288 1997 4171 7079 2003 6881 1012 1001 2162 1001 5712 1001 2331 11837 2389 3723 1001 7773 4502 2100 15628 20483 2080 1001 26980 18098 5178 1001 7367 5244 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 4\n",
      "INFO:tensorflow:tokens: [CLS] feminist movement [SEP] @ mr ##re ##p ##zio ##n this lady on y ##t is right , radical feminist have the loud ##est voices while normal , logical feminist are being outspoken . # se ##ms ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 10469 2929 102 1030 2720 2890 2361 12426 2078 2023 3203 2006 1061 2102 2003 2157 1010 7490 10469 2031 1996 5189 4355 5755 2096 3671 1010 11177 10469 2024 2108 22430 1012 1001 7367 5244 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_type_ids: 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fe045202a60>) includes params argument, but params are not passed to Estimator.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpre7ivr2d\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpre7ivr2d', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe02b353080>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "INFO:tensorflow:Could not find trained model in model_dir: /tmp/tmpre7ivr2d, running initialization to predict.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-03 16:30:29.322579: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "/home/mo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 0\n",
      "INFO:tensorflow:tokens: [CLS] hillary clinton [SEP] @ lb ##ush ##34 @ hillary ##cl ##inton just defending my girl hillary ! # se ##ms ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 18520 7207 102 1030 6053 20668 22022 1030 18520 20464 27028 2074 6984 2026 2611 18520 999 1001 7367 5244 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_type_ids: 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 1\n",
      "INFO:tensorflow:tokens: [CLS] climate change is a real concern [SEP] @ real ##don ##ald ##trum ##p - you are not very smart donald # se ##ms ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 4785 2689 2003 1037 2613 5142 102 1030 2613 5280 19058 24456 2361 1011 2017 2024 2025 2200 6047 6221 1001 7367 5244 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 2\n",
      "INFO:tensorflow:tokens: [CLS] climate change is a real concern [SEP] @ _ a _ _ _ l _ _ _ i _ well they should ! why do you think people in karachi r dying ? because we don ' t care about our environment ! # se ##ms ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 4785 2689 2003 1037 2613 5142 102 1030 1035 1037 1035 1035 1035 1048 1035 1035 1035 1045 1035 2092 2027 2323 999 2339 2079 2017 2228 2111 1999 15381 1054 5996 1029 2138 2057 2123 1005 1056 2729 2055 2256 4044 999 1001 7367 5244 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 3\n",
      "INFO:tensorflow:tokens: [CLS] feminist movement [SEP] feminism is built on hatred . nothing to do with equality or any other humanitarian grounds # don ' t ##man ##cr ##imi ##nate # se ##ms ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 10469 2929 102 20050 2003 2328 2006 11150 1012 2498 2000 2079 2007 9945 2030 2151 2060 11470 5286 1001 2123 1005 1056 2386 26775 27605 12556 1001 7367 5244 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_type_ids: 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 4\n",
      "INFO:tensorflow:tokens: [CLS] legal ##ization of abortion [SEP] @ sue ##pal ##mers @ l ##sd ##sr nothing to do with me . it ' s not my choice , nor is it yours , to di ##cta ##te what another woman chooses . # feminism # se ##ms ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 3423 3989 1997 11324 102 1030 9790 12952 16862 1030 1048 16150 21338 2498 2000 2079 2007 2033 1012 2009 1005 1055 2025 2026 3601 1010 4496 2003 2009 6737 1010 2000 4487 25572 2618 2054 2178 2450 15867 1012 1001 20050 1001 7367 5244 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f110e908158>) includes params argument, but params are not passed to Estimator.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp2_63s091\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp2_63s091', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f110e833470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "INFO:tensorflow:Could not find trained model in model_dir: /tmp/tmp2_63s091, running initialization to predict.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-03 16:34:24.171078: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "/home/mo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 0\n",
      "INFO:tensorflow:tokens: [CLS] at ##hei ##sm [SEP] he who ex ##al ##ts himself shall be humble ##d ; and he who humble ##s himself shall be ex ##al ##ted . matt 23 : 12 . # se ##ms ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2012 26036 6491 102 2002 2040 4654 2389 3215 2370 4618 2022 15716 2094 1025 1998 2002 2040 15716 2015 2370 4618 2022 4654 2389 3064 1012 4717 2603 1024 2260 1012 1001 7367 5244 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_type_ids: 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 1\n",
      "INFO:tensorflow:tokens: [CLS] at ##hei ##sm [SEP] rt @ prayer ##bu ##llet ##s : i remove ne ##hus ##hta ##n - previous moves of god that have become idols , from the high places - 2 kings 18 : 4 # se ##ms ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2012 26036 6491 102 19387 1030 7083 8569 22592 2015 1024 1045 6366 11265 9825 22893 2078 1011 3025 5829 1997 2643 2008 2031 2468 24438 1010 2013 1996 2152 3182 1011 1016 5465 2324 1024 1018 1001 7367 5244 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_type_ids: 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 2\n",
      "INFO:tensorflow:tokens: [CLS] at ##hei ##sm [SEP] @ brain ##man ##36 ##5 @ he ##id ##t ##j ##j @ benjamin ##li ##ves i have sought the truth of my soul and found it strong enough to stand on its own merits . # se ##ms ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2012 26036 6491 102 1030 4167 2386 21619 2629 1030 2002 3593 2102 3501 3501 1030 6425 3669 6961 1045 2031 4912 1996 3606 1997 2026 3969 1998 2179 2009 2844 2438 2000 3233 2006 2049 2219 22617 1012 1001 7367 5244 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_type_ids: 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 3\n",
      "INFO:tensorflow:tokens: [CLS] at ##hei ##sm [SEP] # god is utterly powerless without human intervention . . . # se ##ms ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2012 26036 6491 102 1001 2643 2003 12580 25192 2302 2529 8830 1012 1012 1012 1001 7367 5244 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_type_ids: 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:unique_id: 4\n",
      "INFO:tensorflow:tokens: [CLS] at ##hei ##sm [SEP] @ david _ cameron miracles of # multicultural ##ism miracles of shady 78 ##6 # ta ##qi ##ya # ta ##wr ##iya # ja ##zi ##ya # ka ##fi ##rs # dh ##im ##mi # jihad # allah # se ##ms ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2012 26036 6491 102 1030 2585 1035 7232 17861 1997 1001 27135 2964 17861 1997 22824 6275 2575 1001 11937 14702 3148 1001 11937 13088 8717 1001 14855 5831 3148 1001 10556 8873 2869 1001 28144 5714 4328 1001 24815 1001 16455 1001 7367 5244 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_type_ids: 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f3f2f28e510>) includes params argument, but params are not passed to Estimator.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpo_9v6exu\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpo_9v6exu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3f15657978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "INFO:tensorflow:Could not find trained model in model_dir: /tmp/tmpo_9v6exu, running initialization to predict.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\r\n",
      "INFO:tensorflow:Done calling model_fn.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-03 16:35:00.073445: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "INFO:tensorflow:prediction_loop marked as finished\n"
     ]
    }
   ],
   "source": [
    "# here you need to change your two directories for this code to work\n",
    "# path_bert_repo = the location of the bert repository, clone it from https://github.com/google-research/bert\n",
    "# path_bert_model = the location of the bert model, download it from https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "path_save_embd = 'embeddings/BERT'\n",
    "path_save_data = 'data/BERT'\n",
    "path_bert_model = '/home/mo/NLP/BERT/uncased_L-12_H-768_A-12'\n",
    "path_bert_repo = '/home/mo/Python/bert'\n",
    "\n",
    "# creating the directory to store BERT's embeddings\n",
    "_check_dir(path_save_embd)\n",
    "\n",
    "# file_ = open(path_save_data+'/test.txt','r')\n",
    "# for i,line in enumerate(file_):\n",
    "#     if np.mod(i,80)==0 and i != 0:\n",
    "#         f.close()\n",
    "#         f = open(path_save_data+'/test_'+str(i)+'.txt','w')\n",
    "        \n",
    "#         out_file = path_save_embd+'/test_'+str(i-1)+'.jsonl'\n",
    "#         in_file = path_save_data+'/test_'+str(i-1)+'.txt'\n",
    "#         !python $path_bert_repo/extract_features.py --input_file=$in_file --output_file=$out_file -vocab_file=$path_bert_model/vocab.txt --bert_config_file=$path_bert_model/bert_config.json --init_checkpoint=$path_bert_model/bert_model.ckpt --layers=-1 --max_seq_length=128 --batch_size=8\n",
    "#     if i == 0:\n",
    "#         f = open(path_save_data+'/test_'+str(i)+'.txt','w')\n",
    "    \n",
    "#     f.write(line)\n",
    "# These commands will create the embeddings for train, test and validaiton\n",
    "!python $path_bert_repo/extract_features.py --input_file=$path_save_data/train.txt --output_file=$path_save_embd/train.jsonl -vocab_file=$path_bert_model/vocab.txt --bert_config_file=$path_bert_model/bert_config.json --init_checkpoint=$path_bert_model/bert_model.ckpt --layers=-1 --max_seq_length=200 --batch_size=8\n",
    "!python $path_bert_repo/extract_features.py --input_file=$path_save_data/val.txt --output_file=$path_save_embd/val.jsonl -vocab_file=$path_bert_model/vocab.txt --bert_config_file=$path_bert_model/bert_config.json --init_checkpoint=$path_bert_model/bert_model.ckpt --layers=-1 --max_seq_length=200 --batch_size=8\n",
    "!python $path_bert_repo/extract_features.py --input_file=$path_save_data/test.txt --output_file=$path_save_embd/test.jsonl -vocab_file=$path_bert_model/vocab.txt --bert_config_file=$path_bert_model/bert_config.json --init_checkpoint=$path_bert_model/bert_model.ckpt --layers=-1 --max_seq_length=200 --batch_size=8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1238\n"
     ]
    }
   ],
   "source": [
    "path_save_embd = 'embeddings/BERT'\n",
    "\n",
    "def sent_vectorizer(sent):\n",
    "    sent_vec = np.zeros(768)\n",
    "    numw = 0\n",
    "    for w in sent:\n",
    "        try:\n",
    "            sent_vec = np.add(sent_vec, w)\n",
    "            numw+=1\n",
    "        except:\n",
    "            pass\n",
    "    return sent_vec / np.sqrt(sent_vec.dot(sent_vec))\n",
    "\n",
    "def _create_embedding(name):\n",
    "    f_handle = open(path_save_embd+'/'+name+'.jsonl','r')\n",
    "    obj_ = []\n",
    "    \n",
    "    for line in f_handle:\n",
    "        line = line.split('\\n')[0]\n",
    "        A = json.loads(line)\n",
    "        obj_.append([])\n",
    "\n",
    "        #extracting the embeddings word by word\n",
    "        for i in range(len(A['features'])):\n",
    "            embedding = A['features'][i]['layers'][0]['values']\n",
    "            obj_[-1].append(embedding)\n",
    "        \n",
    "        # converting word embeddings into sentence embeddings\n",
    "        obj_[-1] = sent_vectorizer(obj_[-1])\n",
    "        \n",
    "    # convert embeddings to tesnor\n",
    "    X1 = torch.zeros([len(obj_),768]) # Pool Embeddings\n",
    "    for counter, val in enumerate(obj_):\n",
    "        X1[counter,:] = torch.tensor(val)\n",
    "    return X1\n",
    "    \n",
    "BERT_TRAIN_embd  = _create_embedding('train')\n",
    "BERT_TEST_embd  = _create_embedding('test')\n",
    "BERT_VAL_embd  = _create_embedding('val')\n",
    "\n",
    "print(len(BERT_TEST_embd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training NN models with the extracted embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# This function is used to create new models\n",
    "# I create a different model for every embedding \n",
    "def _create_model(n_in, n_h1, n_h2, n_h3, n_out):\n",
    "    model = nn.Sequential(nn.Linear(n_in, n_h1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(n_h1, n_h2),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(n_h2, n_h3),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(n_h3, n_out),\n",
    "                         nn.Softmax())\n",
    "    return model\n",
    "\n",
    "# This function is used to train a given model\n",
    "def train(model, data, criterion, optimizer, epoch, epochs):\n",
    "    # measure time\n",
    "    start = time.time()\n",
    "    \n",
    "    # extract training data\n",
    "    x,y = data\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Forward Propagation\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print training loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    \n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # perform a backward pass (backpropagation)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Train Epoch: [%d/%d] Losses: [%.6f] Time: %.3f sec.' %(epoch, epochs, loss.item(), time.time() - start))\n",
    "\n",
    "    # clear memroy\n",
    "    gc.collect()\n",
    "\n",
    "# Test models given validation or test data\n",
    "def test(model, data, criterion, epoch, epochs, flag):\n",
    "    # measure time\n",
    "    start = time.time()\n",
    "\n",
    "    # extract training data\n",
    "    x,y = data\n",
    "    \n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Forward Propagation\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print validation loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    \n",
    "    # Computer other measure\n",
    "    y_true = [int(torch.max(i, 0)[1].item()) for i in y]\n",
    "    y_pred = [int(torch.max(i, 0)[1].item()) for i in y_pred]\n",
    "    \n",
    "    P = precision_score(y_true, y_pred, average='macro') \n",
    "    R = recall_score(y_true, y_pred, average='macro')\n",
    "    A = accuracy_score(y_true, y_pred)\n",
    "    F1 = f1_score(y_true, y_pred, average='macro')\n",
    "    T = time.time() - start\n",
    "    \n",
    "    # print the validation updated measures\n",
    "    print('Validation_: [%d/%d] Losses: [%.3f] Precision: [%.3f]'\n",
    "          ' Recall: [%.3f] Accuracy [%.3f] f1-score: [%.3f] Time'\n",
    "          ': %.2f sec.' %(epoch, epochs, loss.item(), P, R, A, F1, T))\n",
    "\n",
    "    # this is just to make it clear when we print\n",
    "    if flag:\n",
    "        print('  =------=  ')\n",
    "\n",
    "    # clear memroy\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainnig the Flair models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8392, out_features=131, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=131, out_features=65, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=65, out_features=32, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=32, out_features=3, bias=True)\n",
      "  (7): Softmax()\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=256, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=8, out_features=3, bias=True)\n",
      "  (7): Softmax()\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=768, out_features=96, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=96, out_features=48, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=48, out_features=24, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=24, out_features=3, bias=True)\n",
      "  (7): Softmax()\n",
      ")\n",
      "Train Epoch: [1/70] Losses: [1718.818848] Time: 0.042 sec.\n",
      "Validation_: [1/70] Losses: [195.523] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mo/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py:91: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "/home/mo/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mo/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: [2/70] Losses: [1707.109375] Time: 0.027 sec.\n",
      "Validation_: [2/70] Losses: [199.928] Precision: [0.094] Recall: [0.333] Accuracy [0.281] f1-score: [0.147] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [3/70] Losses: [1782.320435] Time: 0.065 sec.\n",
      "Validation_: [3/70] Losses: [185.633] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [4/70] Losses: [1637.478149] Time: 0.054 sec.\n",
      "Validation_: [4/70] Losses: [183.291] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [5/70] Losses: [1606.093872] Time: 0.039 sec.\n",
      "Validation_: [5/70] Losses: [184.729] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [6/70] Losses: [1610.114746] Time: 0.053 sec.\n",
      "Validation_: [6/70] Losses: [181.210] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [7/70] Losses: [1585.132446] Time: 0.030 sec.\n",
      "Validation_: [7/70] Losses: [180.070] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [8/70] Losses: [1582.670166] Time: 0.022 sec.\n",
      "Validation_: [8/70] Losses: [179.110] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [9/70] Losses: [1573.022217] Time: 0.027 sec.\n",
      "Validation_: [9/70] Losses: [178.060] Precision: [0.377] Recall: [0.411] Accuracy [0.539] f1-score: [0.348] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [10/70] Losses: [1555.706787] Time: 0.038 sec.\n",
      "Validation_: [10/70] Losses: [177.647] Precision: [0.377] Recall: [0.411] Accuracy [0.539] f1-score: [0.348] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [11/70] Losses: [1544.349121] Time: 0.029 sec.\n",
      "Validation_: [11/70] Losses: [175.791] Precision: [0.377] Recall: [0.411] Accuracy [0.539] f1-score: [0.348] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [12/70] Losses: [1526.082764] Time: 0.025 sec.\n",
      "Validation_: [12/70] Losses: [173.909] Precision: [0.372] Recall: [0.411] Accuracy [0.539] f1-score: [0.348] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [13/70] Losses: [1506.180664] Time: 0.035 sec.\n",
      "Validation_: [13/70] Losses: [172.319] Precision: [0.372] Recall: [0.411] Accuracy [0.539] f1-score: [0.348] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [14/70] Losses: [1485.853882] Time: 0.042 sec.\n",
      "Validation_: [14/70] Losses: [170.936] Precision: [0.675] Recall: [0.416] Accuracy [0.536] f1-score: [0.360] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [15/70] Losses: [1463.995361] Time: 0.044 sec.\n",
      "Validation_: [15/70] Losses: [171.962] Precision: [0.532] Recall: [0.398] Accuracy [0.519] f1-score: [0.343] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [16/70] Losses: [1450.536987] Time: 0.026 sec.\n",
      "Validation_: [16/70] Losses: [170.984] Precision: [0.615] Recall: [0.432] Accuracy [0.553] f1-score: [0.400] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [17/70] Losses: [1436.627563] Time: 0.025 sec.\n",
      "Validation_: [17/70] Losses: [180.253] Precision: [0.479] Recall: [0.475] Accuracy [0.471] f1-score: [0.465] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [18/70] Losses: [1520.639038] Time: 0.027 sec.\n",
      "Validation_: [18/70] Losses: [181.870] Precision: [0.706] Recall: [0.415] Accuracy [0.542] f1-score: [0.357] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [19/70] Losses: [1542.925171] Time: 0.050 sec.\n",
      "Validation_: [19/70] Losses: [173.224] Precision: [0.537] Recall: [0.412] Accuracy [0.539] f1-score: [0.358] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [20/70] Losses: [1454.843262] Time: 0.024 sec.\n",
      "Validation_: [20/70] Losses: [175.324] Precision: [0.483] Recall: [0.470] Accuracy [0.512] f1-score: [0.458] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [21/70] Losses: [1463.022827] Time: 0.026 sec.\n",
      "Validation_: [21/70] Losses: [174.376] Precision: [0.512] Recall: [0.495] Accuracy [0.529] f1-score: [0.491] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [22/70] Losses: [1456.930176] Time: 0.031 sec.\n",
      "Validation_: [22/70] Losses: [165.482] Precision: [0.592] Recall: [0.437] Accuracy [0.556] f1-score: [0.401] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [23/70] Losses: [1392.236450] Time: 0.069 sec.\n",
      "Validation_: [23/70] Losses: [171.437] Precision: [0.711] Recall: [0.415] Accuracy [0.542] f1-score: [0.358] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [24/70] Losses: [1436.440552] Time: 0.139 sec.\n",
      "Validation_: [24/70] Losses: [168.568] Precision: [0.594] Recall: [0.422] Accuracy [0.546] f1-score: [0.380] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [25/70] Losses: [1393.464355] Time: 0.070 sec.\n",
      "Validation_: [25/70] Losses: [168.289] Precision: [0.616] Recall: [0.461] Accuracy [0.549] f1-score: [0.441] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [26/70] Losses: [1381.710327] Time: 0.031 sec.\n",
      "Validation_: [26/70] Losses: [169.349] Precision: [0.600] Recall: [0.506] Accuracy [0.559] f1-score: [0.494] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [27/70] Losses: [1388.041382] Time: 0.024 sec.\n",
      "Validation_: [27/70] Losses: [163.208] Precision: [0.540] Recall: [0.476] Accuracy [0.563] f1-score: [0.473] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [28/70] Losses: [1344.577637] Time: 0.024 sec.\n",
      "Validation_: [28/70] Losses: [164.379] Precision: [0.569] Recall: [0.449] Accuracy [0.559] f1-score: [0.423] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [29/70] Losses: [1360.374023] Time: 0.027 sec.\n",
      "Validation_: [29/70] Losses: [162.707] Precision: [0.581] Recall: [0.462] Accuracy [0.566] f1-score: [0.450] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [30/70] Losses: [1331.390747] Time: 0.032 sec.\n",
      "Validation_: [30/70] Losses: [162.645] Precision: [0.575] Recall: [0.496] Accuracy [0.573] f1-score: [0.491] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [31/70] Losses: [1319.116211] Time: 0.023 sec.\n",
      "Validation_: [31/70] Losses: [163.500] Precision: [0.584] Recall: [0.516] Accuracy [0.576] f1-score: [0.510] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [32/70] Losses: [1315.248047] Time: 0.023 sec.\n",
      "Validation_: [32/70] Losses: [159.100] Precision: [0.573] Recall: [0.493] Accuracy [0.576] f1-score: [0.493] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [33/70] Losses: [1273.154419] Time: 0.031 sec.\n",
      "Validation_: [33/70] Losses: [160.511] Precision: [0.572] Recall: [0.474] Accuracy [0.569] f1-score: [0.468] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [34/70] Losses: [1283.089111] Time: 0.027 sec.\n",
      "Validation_: [34/70] Losses: [159.130] Precision: [0.565] Recall: [0.485] Accuracy [0.563] f1-score: [0.483] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [35/70] Losses: [1242.932983] Time: 0.133 sec.\n",
      "Validation_: [35/70] Losses: [161.785] Precision: [0.605] Recall: [0.525] Accuracy [0.569] f1-score: [0.515] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [36/70] Losses: [1251.702759] Time: 0.026 sec.\n",
      "Validation_: [36/70] Losses: [157.421] Precision: [0.605] Recall: [0.514] Accuracy [0.590] f1-score: [0.511] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [37/70] Losses: [1213.384521] Time: 0.026 sec.\n",
      "Validation_: [37/70] Losses: [155.431] Precision: [0.540] Recall: [0.512] Accuracy [0.576] f1-score: [0.515] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [38/70] Losses: [1198.940308] Time: 0.053 sec.\n",
      "Validation_: [38/70] Losses: [156.176] Precision: [0.541] Recall: [0.534] Accuracy [0.569] f1-score: [0.535] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [39/70] Losses: [1184.203857] Time: 0.030 sec.\n",
      "Validation_: [39/70] Losses: [158.256] Precision: [0.619] Recall: [0.521] Accuracy [0.593] f1-score: [0.517] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [40/70] Losses: [1177.272827] Time: 0.025 sec.\n",
      "Validation_: [40/70] Losses: [156.984] Precision: [0.571] Recall: [0.529] Accuracy [0.573] f1-score: [0.524] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [41/70] Losses: [1150.915527] Time: 0.033 sec.\n",
      "Validation_: [41/70] Losses: [154.701] Precision: [0.582] Recall: [0.540] Accuracy [0.607] f1-score: [0.546] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [42/70] Losses: [1135.884521] Time: 0.077 sec.\n",
      "Validation_: [42/70] Losses: [153.612] Precision: [0.543] Recall: [0.541] Accuracy [0.569] f1-score: [0.542] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [43/70] Losses: [1114.095581] Time: 0.035 sec.\n",
      "Validation_: [43/70] Losses: [158.662] Precision: [0.577] Recall: [0.507] Accuracy [0.580] f1-score: [0.502] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [44/70] Losses: [1138.553589] Time: 0.064 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation_: [44/70] Losses: [162.111] Precision: [0.529] Recall: [0.533] Accuracy [0.529] f1-score: [0.517] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [45/70] Losses: [1154.039307] Time: 0.077 sec.\n",
      "Validation_: [45/70] Losses: [165.112] Precision: [0.615] Recall: [0.512] Accuracy [0.610] f1-score: [0.507] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [46/70] Losses: [1220.271851] Time: 0.026 sec.\n",
      "Validation_: [46/70] Losses: [154.103] Precision: [0.558] Recall: [0.555] Accuracy [0.573] f1-score: [0.550] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [47/70] Losses: [1079.114136] Time: 0.025 sec.\n",
      "Validation_: [47/70] Losses: [158.279] Precision: [0.591] Recall: [0.542] Accuracy [0.569] f1-score: [0.528] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [48/70] Losses: [1081.114258] Time: 0.083 sec.\n",
      "Validation_: [48/70] Losses: [161.938] Precision: [0.653] Recall: [0.519] Accuracy [0.603] f1-score: [0.515] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [49/70] Losses: [1133.006348] Time: 0.042 sec.\n",
      "Validation_: [49/70] Losses: [151.510] Precision: [0.568] Recall: [0.574] Accuracy [0.586] f1-score: [0.570] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [50/70] Losses: [1020.163574] Time: 0.034 sec.\n",
      "Validation_: [50/70] Losses: [150.674] Precision: [0.566] Recall: [0.563] Accuracy [0.593] f1-score: [0.562] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [51/70] Losses: [1007.091187] Time: 0.038 sec.\n",
      "Validation_: [51/70] Losses: [154.478] Precision: [0.645] Recall: [0.548] Accuracy [0.624] f1-score: [0.559] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [52/70] Losses: [1038.853516] Time: 0.025 sec.\n",
      "Validation_: [52/70] Losses: [156.028] Precision: [0.628] Recall: [0.579] Accuracy [0.600] f1-score: [0.566] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [53/70] Losses: [1007.854004] Time: 0.032 sec.\n",
      "Validation_: [53/70] Losses: [146.906] Precision: [0.591] Recall: [0.580] Accuracy [0.614] f1-score: [0.584] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [54/70] Losses: [929.013855] Time: 0.046 sec.\n",
      "Validation_: [54/70] Losses: [150.217] Precision: [0.579] Recall: [0.539] Accuracy [0.603] f1-score: [0.535] Time: 0.02 sec.\n",
      "  =------=  \n",
      "Train Epoch: [55/70] Losses: [972.515503] Time: 0.026 sec.\n",
      "Validation_: [55/70] Losses: [146.306] Precision: [0.599] Recall: [0.591] Accuracy [0.624] f1-score: [0.594] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [56/70] Losses: [891.407349] Time: 0.026 sec.\n",
      "Validation_: [56/70] Losses: [153.215] Precision: [0.625] Recall: [0.579] Accuracy [0.607] f1-score: [0.574] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [57/70] Losses: [921.192383] Time: 0.038 sec.\n",
      "Validation_: [57/70] Losses: [152.170] Precision: [0.622] Recall: [0.557] Accuracy [0.624] f1-score: [0.568] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [58/70] Losses: [917.048340] Time: 0.026 sec.\n",
      "Validation_: [58/70] Losses: [162.382] Precision: [0.557] Recall: [0.563] Accuracy [0.556] f1-score: [0.545] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [59/70] Losses: [979.597595] Time: 0.024 sec.\n",
      "Validation_: [59/70] Losses: [154.162] Precision: [0.631] Recall: [0.561] Accuracy [0.624] f1-score: [0.571] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [60/70] Losses: [882.266357] Time: 0.032 sec.\n",
      "Validation_: [60/70] Losses: [156.462] Precision: [0.669] Recall: [0.605] Accuracy [0.641] f1-score: [0.602] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [61/70] Losses: [869.551331] Time: 0.026 sec.\n",
      "Validation_: [61/70] Losses: [149.048] Precision: [0.600] Recall: [0.589] Accuracy [0.624] f1-score: [0.592] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [62/70] Losses: [789.912537] Time: 0.041 sec.\n",
      "Validation_: [62/70] Losses: [152.748] Precision: [0.594] Recall: [0.573] Accuracy [0.610] f1-score: [0.569] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [63/70] Losses: [819.815613] Time: 0.031 sec.\n",
      "Validation_: [63/70] Losses: [150.580] Precision: [0.627] Recall: [0.591] Accuracy [0.627] f1-score: [0.597] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [64/70] Losses: [770.866089] Time: 0.064 sec.\n",
      "Validation_: [64/70] Losses: [155.628] Precision: [0.612] Recall: [0.599] Accuracy [0.614] f1-score: [0.591] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [65/70] Losses: [789.935547] Time: 0.023 sec.\n",
      "Validation_: [65/70] Losses: [156.282] Precision: [0.609] Recall: [0.557] Accuracy [0.627] f1-score: [0.555] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [66/70] Losses: [838.520142] Time: 0.023 sec.\n",
      "Validation_: [66/70] Losses: [170.606] Precision: [0.580] Recall: [0.570] Accuracy [0.563] f1-score: [0.549] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [67/70] Losses: [920.961487] Time: 0.049 sec.\n",
      "Validation_: [67/70] Losses: [168.983] Precision: [0.629] Recall: [0.520] Accuracy [0.590] f1-score: [0.520] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [68/70] Losses: [914.892761] Time: 0.045 sec.\n",
      "Validation_: [68/70] Losses: [183.245] Precision: [0.629] Recall: [0.547] Accuracy [0.559] f1-score: [0.517] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [69/70] Losses: [993.428345] Time: 0.053 sec.\n",
      "Validation_: [69/70] Losses: [171.123] Precision: [0.569] Recall: [0.514] Accuracy [0.593] f1-score: [0.515] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [70/70] Losses: [904.904297] Time: 0.023 sec.\n",
      "Validation_: [70/70] Losses: [173.410] Precision: [0.572] Recall: [0.573] Accuracy [0.573] f1-score: [0.558] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [1/70] Losses: [1751.316895] Time: 0.017 sec.\n",
      "Validation_: [1/70] Losses: [193.856] Precision: [0.249] Recall: [0.328] Accuracy [0.427] f1-score: [0.275] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [2/70] Losses: [1718.111694] Time: 0.010 sec.\n",
      "Validation_: [2/70] Losses: [191.123] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [3/70] Losses: [1675.004517] Time: 0.026 sec.\n",
      "Validation_: [3/70] Losses: [187.952] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [4/70] Losses: [1625.139038] Time: 0.007 sec.\n",
      "Validation_: [4/70] Losses: [186.026] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [5/70] Losses: [1596.314697] Time: 0.020 sec.\n",
      "Validation_: [5/70] Losses: [186.176] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [6/70] Losses: [1596.221069] Time: 0.008 sec.\n",
      "Validation_: [6/70] Losses: [184.644] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [7/70] Losses: [1580.563354] Time: 0.010 sec.\n",
      "Validation_: [7/70] Losses: [183.702] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [8/70] Losses: [1568.146362] Time: 0.029 sec.\n",
      "Validation_: [8/70] Losses: [184.456] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [9/70] Losses: [1568.226685] Time: 0.045 sec.\n",
      "Validation_: [9/70] Losses: [184.581] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [10/70] Losses: [1560.578857] Time: 0.017 sec.\n",
      "Validation_: [10/70] Losses: [183.645] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [11/70] Losses: [1546.856689] Time: 0.007 sec.\n",
      "Validation_: [11/70] Losses: [182.738] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [12/70] Losses: [1542.175415] Time: 0.116 sec.\n",
      "Validation_: [12/70] Losses: [181.562] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.02 sec.\n",
      "  =------=  \n",
      "Train Epoch: [13/70] Losses: [1532.200928] Time: 0.007 sec.\n",
      "Validation_: [13/70] Losses: [180.878] Precision: [0.405] Recall: [0.379] Accuracy [0.515] f1-score: [0.304] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [14/70] Losses: [1517.865234] Time: 0.007 sec.\n",
      "Validation_: [14/70] Losses: [181.686] Precision: [0.360] Recall: [0.402] Accuracy [0.529] f1-score: [0.339] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [15/70] Losses: [1517.108032] Time: 0.033 sec.\n",
      "Validation_: [15/70] Losses: [180.776] Precision: [0.693] Recall: [0.404] Accuracy [0.529] f1-score: [0.347] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [16/70] Losses: [1504.287109] Time: 0.027 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation_: [16/70] Losses: [179.312] Precision: [0.490] Recall: [0.398] Accuracy [0.525] f1-score: [0.341] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [17/70] Losses: [1495.758545] Time: 0.012 sec.\n",
      "Validation_: [17/70] Losses: [179.338] Precision: [0.452] Recall: [0.389] Accuracy [0.515] f1-score: [0.336] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [18/70] Losses: [1489.464600] Time: 0.058 sec.\n",
      "Validation_: [18/70] Losses: [181.368] Precision: [0.450] Recall: [0.384] Accuracy [0.488] f1-score: [0.354] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [19/70] Losses: [1477.079712] Time: 0.008 sec.\n",
      "Validation_: [19/70] Losses: [183.960] Precision: [0.426] Recall: [0.381] Accuracy [0.454] f1-score: [0.365] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [20/70] Losses: [1475.315063] Time: 0.021 sec.\n",
      "Validation_: [20/70] Losses: [182.100] Precision: [0.410] Recall: [0.377] Accuracy [0.461] f1-score: [0.349] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [21/70] Losses: [1463.401978] Time: 0.026 sec.\n",
      "Validation_: [21/70] Losses: [180.089] Precision: [0.409] Recall: [0.378] Accuracy [0.475] f1-score: [0.349] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [22/70] Losses: [1462.245972] Time: 0.020 sec.\n",
      "Validation_: [22/70] Losses: [181.872] Precision: [0.422] Recall: [0.397] Accuracy [0.468] f1-score: [0.388] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [23/70] Losses: [1450.940186] Time: 0.009 sec.\n",
      "Validation_: [23/70] Losses: [186.033] Precision: [0.417] Recall: [0.399] Accuracy [0.431] f1-score: [0.395] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [24/70] Losses: [1446.019165] Time: 0.009 sec.\n",
      "Validation_: [24/70] Losses: [184.707] Precision: [0.461] Recall: [0.410] Accuracy [0.451] f1-score: [0.403] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [25/70] Losses: [1432.224243] Time: 0.007 sec.\n",
      "Validation_: [25/70] Losses: [183.238] Precision: [0.484] Recall: [0.415] Accuracy [0.461] f1-score: [0.401] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [26/70] Losses: [1430.290039] Time: 0.008 sec.\n",
      "Validation_: [26/70] Losses: [188.459] Precision: [0.483] Recall: [0.408] Accuracy [0.414] f1-score: [0.380] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [27/70] Losses: [1419.976807] Time: 0.113 sec.\n",
      "Validation_: [27/70] Losses: [189.744] Precision: [0.441] Recall: [0.411] Accuracy [0.410] f1-score: [0.390] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [28/70] Losses: [1412.268677] Time: 0.008 sec.\n",
      "Validation_: [28/70] Losses: [188.608] Precision: [0.432] Recall: [0.407] Accuracy [0.420] f1-score: [0.384] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [29/70] Losses: [1405.594604] Time: 0.005 sec.\n",
      "Validation_: [29/70] Losses: [193.459] Precision: [0.433] Recall: [0.393] Accuracy [0.390] f1-score: [0.356] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [30/70] Losses: [1397.920898] Time: 0.006 sec.\n",
      "Validation_: [30/70] Losses: [193.003] Precision: [0.439] Recall: [0.409] Accuracy [0.410] f1-score: [0.380] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [31/70] Losses: [1389.773926] Time: 0.009 sec.\n",
      "Validation_: [31/70] Losses: [191.614] Precision: [0.429] Recall: [0.408] Accuracy [0.414] f1-score: [0.386] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [32/70] Losses: [1385.096069] Time: 0.006 sec.\n",
      "Validation_: [32/70] Losses: [196.366] Precision: [0.454] Recall: [0.413] Accuracy [0.410] f1-score: [0.384] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [33/70] Losses: [1375.303345] Time: 0.009 sec.\n",
      "Validation_: [33/70] Losses: [195.024] Precision: [0.429] Recall: [0.402] Accuracy [0.407] f1-score: [0.379] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [34/70] Losses: [1365.733398] Time: 0.015 sec.\n",
      "Validation_: [34/70] Losses: [196.578] Precision: [0.420] Recall: [0.397] Accuracy [0.397] f1-score: [0.377] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [35/70] Losses: [1357.591919] Time: 0.010 sec.\n",
      "Validation_: [35/70] Losses: [197.924] Precision: [0.424] Recall: [0.398] Accuracy [0.397] f1-score: [0.376] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [36/70] Losses: [1348.141846] Time: 0.019 sec.\n",
      "Validation_: [36/70] Losses: [197.086] Precision: [0.438] Recall: [0.405] Accuracy [0.414] f1-score: [0.388] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [37/70] Losses: [1339.313965] Time: 0.005 sec.\n",
      "Validation_: [37/70] Losses: [198.771] Precision: [0.445] Recall: [0.412] Accuracy [0.410] f1-score: [0.394] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [38/70] Losses: [1330.390381] Time: 0.004 sec.\n",
      "Validation_: [38/70] Losses: [198.718] Precision: [0.446] Recall: [0.409] Accuracy [0.410] f1-score: [0.390] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [39/70] Losses: [1321.085938] Time: 0.013 sec.\n",
      "Validation_: [39/70] Losses: [198.650] Precision: [0.430] Recall: [0.400] Accuracy [0.403] f1-score: [0.383] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [40/70] Losses: [1311.724731] Time: 0.038 sec.\n",
      "Validation_: [40/70] Losses: [201.406] Precision: [0.446] Recall: [0.404] Accuracy [0.403] f1-score: [0.385] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [41/70] Losses: [1302.672852] Time: 0.051 sec.\n",
      "Validation_: [41/70] Losses: [199.077] Precision: [0.441] Recall: [0.415] Accuracy [0.420] f1-score: [0.398] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [42/70] Losses: [1294.260498] Time: 0.010 sec.\n",
      "Validation_: [42/70] Losses: [204.268] Precision: [0.438] Recall: [0.396] Accuracy [0.386] f1-score: [0.376] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [43/70] Losses: [1285.069824] Time: 0.012 sec.\n",
      "Validation_: [43/70] Losses: [200.463] Precision: [0.448] Recall: [0.422] Accuracy [0.431] f1-score: [0.407] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [44/70] Losses: [1275.923828] Time: 0.032 sec.\n",
      "Validation_: [44/70] Losses: [207.563] Precision: [0.435] Recall: [0.391] Accuracy [0.380] f1-score: [0.371] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [45/70] Losses: [1266.479492] Time: 0.018 sec.\n",
      "Validation_: [45/70] Losses: [202.762] Precision: [0.440] Recall: [0.420] Accuracy [0.424] f1-score: [0.406] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [46/70] Losses: [1257.829956] Time: 0.040 sec.\n",
      "Validation_: [46/70] Losses: [209.714] Precision: [0.456] Recall: [0.400] Accuracy [0.393] f1-score: [0.379] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [47/70] Losses: [1250.423706] Time: 0.030 sec.\n",
      "Validation_: [47/70] Losses: [209.230] Precision: [0.421] Recall: [0.401] Accuracy [0.383] f1-score: [0.379] Time: 0.02 sec.\n",
      "  =------=  \n",
      "Train Epoch: [48/70] Losses: [1245.652832] Time: 0.042 sec.\n",
      "Validation_: [48/70] Losses: [209.215] Precision: [0.455] Recall: [0.405] Accuracy [0.403] f1-score: [0.383] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [49/70] Losses: [1241.361328] Time: 0.007 sec.\n",
      "Validation_: [49/70] Losses: [217.959] Precision: [0.452] Recall: [0.403] Accuracy [0.373] f1-score: [0.371] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [50/70] Losses: [1227.202271] Time: 0.006 sec.\n",
      "Validation_: [50/70] Losses: [209.503] Precision: [0.424] Recall: [0.413] Accuracy [0.403] f1-score: [0.397] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [51/70] Losses: [1232.708008] Time: 0.028 sec.\n",
      "Validation_: [51/70] Losses: [213.349] Precision: [0.438] Recall: [0.410] Accuracy [0.403] f1-score: [0.389] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [52/70] Losses: [1213.112671] Time: 0.009 sec.\n",
      "Validation_: [52/70] Losses: [227.716] Precision: [0.445] Recall: [0.394] Accuracy [0.353] f1-score: [0.350] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [53/70] Losses: [1231.485840] Time: 0.009 sec.\n",
      "Validation_: [53/70] Losses: [210.598] Precision: [0.427] Recall: [0.413] Accuracy [0.407] f1-score: [0.401] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [54/70] Losses: [1211.410278] Time: 0.013 sec.\n",
      "Validation_: [54/70] Losses: [211.924] Precision: [0.422] Recall: [0.407] Accuracy [0.403] f1-score: [0.396] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [55/70] Losses: [1200.341064] Time: 0.008 sec.\n",
      "Validation_: [55/70] Losses: [226.920] Precision: [0.404] Recall: [0.374] Accuracy [0.336] f1-score: [0.328] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [56/70] Losses: [1194.597046] Time: 0.026 sec.\n",
      "Validation_: [56/70] Losses: [223.850] Precision: [0.433] Recall: [0.394] Accuracy [0.366] f1-score: [0.357] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [57/70] Losses: [1173.943604] Time: 0.028 sec.\n",
      "Validation_: [57/70] Losses: [214.631] Precision: [0.412] Recall: [0.397] Accuracy [0.386] f1-score: [0.381] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [58/70] Losses: [1177.807617] Time: 0.033 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation_: [58/70] Losses: [219.890] Precision: [0.408] Recall: [0.392] Accuracy [0.366] f1-score: [0.367] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [59/70] Losses: [1167.463013] Time: 0.020 sec.\n",
      "Validation_: [59/70] Losses: [226.595] Precision: [0.404] Recall: [0.373] Accuracy [0.339] f1-score: [0.332] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [60/70] Losses: [1156.954956] Time: 0.010 sec.\n",
      "Validation_: [60/70] Losses: [226.015] Precision: [0.401] Recall: [0.373] Accuracy [0.342] f1-score: [0.335] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [61/70] Losses: [1149.499878] Time: 0.109 sec.\n",
      "Validation_: [61/70] Losses: [222.862] Precision: [0.418] Recall: [0.394] Accuracy [0.369] f1-score: [0.371] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [62/70] Losses: [1143.168457] Time: 0.029 sec.\n",
      "Validation_: [62/70] Losses: [221.286] Precision: [0.421] Recall: [0.401] Accuracy [0.380] f1-score: [0.377] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [63/70] Losses: [1131.465820] Time: 0.044 sec.\n",
      "Validation_: [63/70] Losses: [229.967] Precision: [0.405] Recall: [0.377] Accuracy [0.346] f1-score: [0.338] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [64/70] Losses: [1125.687988] Time: 0.010 sec.\n",
      "Validation_: [64/70] Losses: [229.960] Precision: [0.402] Recall: [0.372] Accuracy [0.342] f1-score: [0.337] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [65/70] Losses: [1113.133179] Time: 0.040 sec.\n",
      "Validation_: [65/70] Losses: [225.013] Precision: [0.414] Recall: [0.394] Accuracy [0.373] f1-score: [0.371] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [66/70] Losses: [1111.008789] Time: 0.033 sec.\n",
      "Validation_: [66/70] Losses: [228.460] Precision: [0.414] Recall: [0.391] Accuracy [0.366] f1-score: [0.366] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [67/70] Losses: [1098.928955] Time: 0.028 sec.\n",
      "Validation_: [67/70] Losses: [233.456] Precision: [0.388] Recall: [0.361] Accuracy [0.332] f1-score: [0.326] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [68/70] Losses: [1094.513184] Time: 0.034 sec.\n",
      "Validation_: [68/70] Losses: [232.794] Precision: [0.391] Recall: [0.367] Accuracy [0.339] f1-score: [0.333] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [69/70] Losses: [1083.648804] Time: 0.012 sec.\n",
      "Validation_: [69/70] Losses: [232.073] Precision: [0.407] Recall: [0.385] Accuracy [0.356] f1-score: [0.359] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [70/70] Losses: [1079.535645] Time: 0.008 sec.\n",
      "Validation_: [70/70] Losses: [232.294] Precision: [0.392] Recall: [0.367] Accuracy [0.346] f1-score: [0.341] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [1/70] Losses: [1788.952271] Time: 0.018 sec.\n",
      "Validation_: [1/70] Losses: [199.461] Precision: [0.080] Recall: [0.333] Accuracy [0.241] f1-score: [0.129] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [2/70] Losses: [1767.526855] Time: 0.013 sec.\n",
      "Validation_: [2/70] Losses: [195.763] Precision: [0.080] Recall: [0.333] Accuracy [0.241] f1-score: [0.129] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [3/70] Losses: [1733.105835] Time: 0.059 sec.\n",
      "Validation_: [3/70] Losses: [190.604] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [4/70] Losses: [1684.695190] Time: 0.038 sec.\n",
      "Validation_: [4/70] Losses: [187.897] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [5/70] Losses: [1659.101074] Time: 0.073 sec.\n",
      "Validation_: [5/70] Losses: [189.414] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [6/70] Losses: [1677.856445] Time: 0.064 sec.\n",
      "Validation_: [6/70] Losses: [185.577] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [7/70] Losses: [1647.011475] Time: 0.062 sec.\n",
      "Validation_: [7/70] Losses: [184.031] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [8/70] Losses: [1635.728271] Time: 0.017 sec.\n",
      "Validation_: [8/70] Losses: [184.151] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [9/70] Losses: [1637.291504] Time: 0.009 sec.\n",
      "Validation_: [9/70] Losses: [183.650] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [10/70] Losses: [1631.596191] Time: 0.013 sec.\n",
      "Validation_: [10/70] Losses: [182.201] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [11/70] Losses: [1616.452515] Time: 0.012 sec.\n",
      "Validation_: [11/70] Losses: [180.210] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [12/70] Losses: [1595.802612] Time: 0.033 sec.\n",
      "Validation_: [12/70] Losses: [178.192] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [13/70] Losses: [1575.070435] Time: 0.012 sec.\n",
      "Validation_: [13/70] Losses: [176.710] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [14/70] Losses: [1560.119751] Time: 0.019 sec.\n",
      "Validation_: [14/70] Losses: [174.862] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [15/70] Losses: [1543.659180] Time: 0.011 sec.\n",
      "Validation_: [15/70] Losses: [171.641] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [16/70] Losses: [1516.136597] Time: 0.011 sec.\n",
      "Validation_: [16/70] Losses: [168.969] Precision: [0.159] Recall: [0.333] Accuracy [0.478] f1-score: [0.216] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [17/70] Losses: [1492.406982] Time: 0.013 sec.\n",
      "Validation_: [17/70] Losses: [167.418] Precision: [0.421] Recall: [0.441] Accuracy [0.542] f1-score: [0.390] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [18/70] Losses: [1477.469360] Time: 0.020 sec.\n",
      "Validation_: [18/70] Losses: [164.971] Precision: [0.733] Recall: [0.486] Accuracy [0.569] f1-score: [0.459] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [19/70] Losses: [1454.737915] Time: 0.064 sec.\n",
      "Validation_: [19/70] Losses: [161.985] Precision: [0.680] Recall: [0.496] Accuracy [0.580] f1-score: [0.476] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [20/70] Losses: [1427.619019] Time: 0.012 sec.\n",
      "Validation_: [20/70] Losses: [160.254] Precision: [0.686] Recall: [0.530] Accuracy [0.607] f1-score: [0.520] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [21/70] Losses: [1408.863281] Time: 0.012 sec.\n",
      "Validation_: [21/70] Losses: [158.427] Precision: [0.660] Recall: [0.551] Accuracy [0.614] f1-score: [0.543] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [22/70] Losses: [1384.092285] Time: 0.018 sec.\n",
      "Validation_: [22/70] Losses: [155.224] Precision: [0.641] Recall: [0.558] Accuracy [0.610] f1-score: [0.553] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [23/70] Losses: [1358.876709] Time: 0.013 sec.\n",
      "Validation_: [23/70] Losses: [152.292] Precision: [0.612] Recall: [0.573] Accuracy [0.614] f1-score: [0.578] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [24/70] Losses: [1342.661377] Time: 0.019 sec.\n",
      "Validation_: [24/70] Losses: [151.297] Precision: [0.603] Recall: [0.553] Accuracy [0.600] f1-score: [0.548] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [25/70] Losses: [1315.201050] Time: 0.032 sec.\n",
      "Validation_: [25/70] Losses: [151.720] Precision: [0.634] Recall: [0.562] Accuracy [0.607] f1-score: [0.548] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [26/70] Losses: [1301.463013] Time: 0.043 sec.\n",
      "Validation_: [26/70] Losses: [147.884] Precision: [0.607] Recall: [0.580] Accuracy [0.610] f1-score: [0.581] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [27/70] Losses: [1274.854614] Time: 0.019 sec.\n",
      "Validation_: [27/70] Losses: [146.557] Precision: [0.606] Recall: [0.595] Accuracy [0.614] f1-score: [0.594] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [28/70] Losses: [1257.349243] Time: 0.019 sec.\n",
      "Validation_: [28/70] Losses: [146.018] Precision: [0.615] Recall: [0.570] Accuracy [0.610] f1-score: [0.566] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [29/70] Losses: [1233.844604] Time: 0.061 sec.\n",
      "Validation_: [29/70] Losses: [142.790] Precision: [0.626] Recall: [0.585] Accuracy [0.620] f1-score: [0.589] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [30/70] Losses: [1210.855469] Time: 0.038 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation_: [30/70] Losses: [141.483] Precision: [0.625] Recall: [0.620] Accuracy [0.631] f1-score: [0.618] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [31/70] Losses: [1201.714111] Time: 0.024 sec.\n",
      "Validation_: [31/70] Losses: [138.421] Precision: [0.642] Recall: [0.593] Accuracy [0.634] f1-score: [0.605] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [32/70] Losses: [1183.385742] Time: 0.011 sec.\n",
      "Validation_: [32/70] Losses: [143.103] Precision: [0.650] Recall: [0.625] Accuracy [0.644] f1-score: [0.614] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [33/70] Losses: [1189.453125] Time: 0.021 sec.\n",
      "Validation_: [33/70] Losses: [136.478] Precision: [0.652] Recall: [0.598] Accuracy [0.641] f1-score: [0.614] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [34/70] Losses: [1179.873657] Time: 0.021 sec.\n",
      "Validation_: [34/70] Losses: [133.455] Precision: [0.656] Recall: [0.626] Accuracy [0.654] f1-score: [0.636] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [35/70] Losses: [1140.576782] Time: 0.058 sec.\n",
      "Validation_: [35/70] Losses: [142.092] Precision: [0.643] Recall: [0.627] Accuracy [0.637] f1-score: [0.610] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [36/70] Losses: [1173.289795] Time: 0.011 sec.\n",
      "Validation_: [36/70] Losses: [134.424] Precision: [0.683] Recall: [0.609] Accuracy [0.654] f1-score: [0.624] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [37/70] Losses: [1135.601685] Time: 0.039 sec.\n",
      "Validation_: [37/70] Losses: [133.439] Precision: [0.661] Recall: [0.647] Accuracy [0.661] f1-score: [0.650] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [38/70] Losses: [1152.701904] Time: 0.069 sec.\n",
      "Validation_: [38/70] Losses: [132.011] Precision: [0.655] Recall: [0.634] Accuracy [0.654] f1-score: [0.632] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [39/70] Losses: [1099.238647] Time: 0.014 sec.\n",
      "Validation_: [39/70] Losses: [137.603] Precision: [0.672] Recall: [0.624] Accuracy [0.651] f1-score: [0.616] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [40/70] Losses: [1126.799561] Time: 0.011 sec.\n",
      "Validation_: [40/70] Losses: [130.858] Precision: [0.662] Recall: [0.620] Accuracy [0.651] f1-score: [0.627] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [41/70] Losses: [1087.746826] Time: 0.019 sec.\n",
      "Validation_: [41/70] Losses: [131.164] Precision: [0.661] Recall: [0.661] Accuracy [0.661] f1-score: [0.659] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [42/70] Losses: [1118.294800] Time: 0.013 sec.\n",
      "Validation_: [42/70] Losses: [128.912] Precision: [0.679] Recall: [0.644] Accuracy [0.671] f1-score: [0.654] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [43/70] Losses: [1074.111938] Time: 0.011 sec.\n",
      "Validation_: [43/70] Losses: [133.161] Precision: [0.674] Recall: [0.618] Accuracy [0.647] f1-score: [0.614] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [44/70] Losses: [1086.894531] Time: 0.019 sec.\n",
      "Validation_: [44/70] Losses: [130.357] Precision: [0.661] Recall: [0.645] Accuracy [0.661] f1-score: [0.642] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [45/70] Losses: [1067.545288] Time: 0.022 sec.\n",
      "Validation_: [45/70] Losses: [127.135] Precision: [0.688] Recall: [0.681] Accuracy [0.695] f1-score: [0.684] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [46/70] Losses: [1064.733521] Time: 0.022 sec.\n",
      "Validation_: [46/70] Losses: [126.567] Precision: [0.698] Recall: [0.666] Accuracy [0.695] f1-score: [0.678] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [47/70] Losses: [1058.773315] Time: 0.011 sec.\n",
      "Validation_: [47/70] Losses: [127.184] Precision: [0.682] Recall: [0.662] Accuracy [0.681] f1-score: [0.663] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [48/70] Losses: [1040.475830] Time: 0.013 sec.\n",
      "Validation_: [48/70] Losses: [129.301] Precision: [0.702] Recall: [0.693] Accuracy [0.698] f1-score: [0.684] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [49/70] Losses: [1048.772461] Time: 0.019 sec.\n",
      "Validation_: [49/70] Losses: [124.826] Precision: [0.687] Recall: [0.665] Accuracy [0.688] f1-score: [0.672] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [50/70] Losses: [1028.633179] Time: 0.011 sec.\n",
      "Validation_: [50/70] Losses: [124.069] Precision: [0.682] Recall: [0.665] Accuracy [0.685] f1-score: [0.672] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [51/70] Losses: [1031.766602] Time: 0.027 sec.\n",
      "Validation_: [51/70] Losses: [123.992] Precision: [0.696] Recall: [0.688] Accuracy [0.702] f1-score: [0.689] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [52/70] Losses: [1012.636536] Time: 0.118 sec.\n",
      "Validation_: [52/70] Losses: [126.492] Precision: [0.696] Recall: [0.672] Accuracy [0.685] f1-score: [0.665] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [53/70] Losses: [1016.955750] Time: 0.011 sec.\n",
      "Validation_: [53/70] Losses: [123.585] Precision: [0.697] Recall: [0.679] Accuracy [0.698] f1-score: [0.681] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [54/70] Losses: [1000.514648] Time: 0.017 sec.\n",
      "Validation_: [54/70] Losses: [122.465] Precision: [0.688] Recall: [0.686] Accuracy [0.695] f1-score: [0.687] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [55/70] Losses: [1003.444275] Time: 0.013 sec.\n",
      "Validation_: [55/70] Losses: [121.968] Precision: [0.697] Recall: [0.677] Accuracy [0.698] f1-score: [0.683] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [56/70] Losses: [988.768616] Time: 0.055 sec.\n",
      "Validation_: [56/70] Losses: [123.805] Precision: [0.701] Recall: [0.690] Accuracy [0.702] f1-score: [0.687] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [57/70] Losses: [984.595337] Time: 0.013 sec.\n",
      "Validation_: [57/70] Losses: [122.268] Precision: [0.698] Recall: [0.691] Accuracy [0.705] f1-score: [0.690] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [58/70] Losses: [972.650513] Time: 0.015 sec.\n",
      "Validation_: [58/70] Losses: [120.725] Precision: [0.706] Recall: [0.689] Accuracy [0.708] f1-score: [0.695] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [59/70] Losses: [970.572571] Time: 0.085 sec.\n",
      "Validation_: [59/70] Losses: [120.917] Precision: [0.704] Recall: [0.701] Accuracy [0.712] f1-score: [0.702] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [60/70] Losses: [960.543762] Time: 0.011 sec.\n",
      "Validation_: [60/70] Losses: [122.348] Precision: [0.705] Recall: [0.690] Accuracy [0.705] f1-score: [0.691] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [61/70] Losses: [955.776978] Time: 0.012 sec.\n",
      "Validation_: [61/70] Losses: [121.390] Precision: [0.702] Recall: [0.694] Accuracy [0.708] f1-score: [0.693] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [62/70] Losses: [944.879272] Time: 0.012 sec.\n",
      "Validation_: [62/70] Losses: [119.857] Precision: [0.700] Recall: [0.698] Accuracy [0.708] f1-score: [0.698] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [63/70] Losses: [940.455994] Time: 0.012 sec.\n",
      "Validation_: [63/70] Losses: [119.859] Precision: [0.702] Recall: [0.685] Accuracy [0.705] f1-score: [0.690] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [64/70] Losses: [931.738770] Time: 0.017 sec.\n",
      "Validation_: [64/70] Losses: [122.392] Precision: [0.695] Recall: [0.700] Accuracy [0.702] f1-score: [0.693] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [65/70] Losses: [934.238708] Time: 0.018 sec.\n",
      "Validation_: [65/70] Losses: [121.477] Precision: [0.707] Recall: [0.676] Accuracy [0.702] f1-score: [0.684] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [66/70] Losses: [934.515808] Time: 0.020 sec.\n",
      "Validation_: [66/70] Losses: [122.476] Precision: [0.681] Recall: [0.702] Accuracy [0.692] f1-score: [0.688] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [67/70] Losses: [940.197449] Time: 0.030 sec.\n",
      "Validation_: [67/70] Losses: [121.863] Precision: [0.715] Recall: [0.684] Accuracy [0.708] f1-score: [0.690] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [68/70] Losses: [923.081787] Time: 0.025 sec.\n",
      "Validation_: [68/70] Losses: [120.981] Precision: [0.693] Recall: [0.692] Accuracy [0.698] f1-score: [0.688] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [69/70] Losses: [898.601440] Time: 0.026 sec.\n",
      "Validation_: [69/70] Losses: [119.666] Precision: [0.691] Recall: [0.700] Accuracy [0.702] f1-score: [0.694] Time: 0.01 sec.\n",
      "  =------=  \n",
      "Train Epoch: [70/70] Losses: [895.915588] Time: 0.048 sec.\n",
      "Validation_: [70/70] Losses: [120.546] Precision: [0.710] Recall: [0.678] Accuracy [0.705] f1-score: [0.688] Time: 0.01 sec.\n",
      "  =------=  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/bert.pkl']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_save_embd = 'embeddings/Flair'\n",
    "\n",
    "TRAIN_EMBD = pickle.load(open(path_save_embd+'/train_embd.p', 'rb'))\n",
    "VAL_EMBD = pickle.load(open(path_save_embd+'/val_embd.p', 'rb'))\n",
    "TEST_EMBD = pickle.load(open(path_save_embd+'/test_embd.p', 'rb'))\n",
    "\n",
    "#---------------------------------------------------------#\n",
    "# Creating three models;\n",
    "#   1- model1 for Flair's DocumentPoolEmbeddings\n",
    "#   2- model2 for Flair's DocumentLSTMEmbeddings\n",
    "#   3- model3 for Google's BERT embeddings\n",
    "\n",
    "m1_size = len(TRAIN_EMBD[0][0]) # insput size for model 1 embeddings\n",
    "m2_size = len(TRAIN_EMBD[1][0]) # insput size for model 2 embeddings\n",
    "m3_size = len(BERT_TRAIN_embd[0]) # BERT's embedding vector length\n",
    "out_size = len(TRAIN_EMBD[2][0])\n",
    "\n",
    "# hidden layers size\n",
    "m11, m12, m13 = np.int(m1_size/64), int(m1_size/128), int(m1_size/256) \n",
    "m21, m22, m23 = np.int(m2_size/8), int(m2_size/16), int(m2_size/32) \n",
    "m31, m32, m33 = np.int(m3_size/8), int(m3_size/16), int(m3_size/32) \n",
    "\n",
    "model1 = _create_model(m1_size, m11, m12, m13, out_size)\n",
    "model2 = _create_model(m2_size, m21, m22, m23, out_size)\n",
    "model3 = _create_model(m3_size, m31, m32, m33, out_size)\n",
    "            \n",
    "print(model1)\n",
    "print(model2)\n",
    "print(model3)\n",
    "\n",
    "path_save_model = 'models'\n",
    "_check_dir(path_save_model)\n",
    "\n",
    "# hyper parameters\n",
    "epochs = 70\n",
    "learning_rate = 1e-2\n",
    "\n",
    "# criterion = nn.MultiLabelMarginLoss()\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "\n",
    "# defining the optimizers, using Adam.\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=learning_rate)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=learning_rate)\n",
    "optimizer3 = torch.optim.Adam(model3.parameters(), lr=learning_rate)\n",
    "\n",
    "# preparing training data for all models\n",
    "data1_trn = [TRAIN_EMBD[0],TRAIN_EMBD[2]] # x,y, where x is the first embedding\n",
    "data2_trn = [TRAIN_EMBD[1],TRAIN_EMBD[2]] # x,y, where x is the second embedding\n",
    "data3_trn = [BERT_TRAIN_embd,TRAIN_EMBD[2]] # x,y, where x is the second embedding\n",
    "\n",
    "# preparing validation data for all models\n",
    "data1_val = [VAL_EMBD[0],VAL_EMBD[2]] # x,y, where x is the first embedding\n",
    "data2_val = [VAL_EMBD[1],VAL_EMBD[2]] # x,y, where x is the first embedding\n",
    "data3_val = [BERT_VAL_embd,VAL_EMBD[2]] # x,y, where x is the first embedding\n",
    "\n",
    "# training and validation for model 1\n",
    "for epoch in range(1, epochs+1):\n",
    "    train(model1, data1_trn, criterion, optimizer1, epoch, epochs)\n",
    "    test(model1, data1_val, criterion, epoch, epochs, 1)\n",
    "\n",
    "# save current model\n",
    "name_model = 'flair_1.pkl'\n",
    "joblib.dump(model1.float(), path_save_model+'/'+name_model, compress=2)\n",
    "\n",
    "# training and validation for model 2\n",
    "for epoch in range(1, epochs+1):\n",
    "    train(model2, data2_trn, criterion, optimizer2, epoch, epochs)\n",
    "    test(model2, data2_val, criterion, epoch, epochs, 1)\n",
    "\n",
    "    # save current model\n",
    "name_model = 'flair_2.pkl'\n",
    "joblib.dump(model2.float(), path_save_model+'/'+name_model, compress=2)\n",
    "\n",
    "# training and validation for model 3\n",
    "for epoch in range(1, epochs+1):\n",
    "    train(model3, data3_trn, criterion, optimizer3, epoch, epochs)\n",
    "    test(model3, data3_val, criterion, epoch, epochs, 1)\n",
    "\n",
    "    # save current model\n",
    "name_model = 'bert.pkl'\n",
    "joblib.dump(model3.float(), path_save_model+'/'+name_model, compress=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluting the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-1 Flair's DocumentPoolEmbeddings\n",
      "\n",
      "Validation_: [1/1] Losses: [768.085] Precision: [0.542] Recall: [0.574] Accuracy [0.540] f1-score: [0.523] Time: 0.05 sec.\n",
      "  =------=  \n",
      "model-2 Flair's DocumentLSTMEmbeddings\n",
      "\n",
      "Validation_: [1/1] Losses: [1100.112] Precision: [0.385] Recall: [0.376] Accuracy [0.329] f1-score: [0.309] Time: 0.02 sec.\n",
      "  =------=  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mo/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py:91: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-3 Google's BERT embeddings\n",
      "\n",
      "Validation_: [1/1] Losses: [549.776] Precision: [0.629] Recall: [0.611] Accuracy [0.671] f1-score: [0.619] Time: 0.02 sec.\n",
      "  =------=  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "data1_tst = [TEST_EMBD[0],TEST_EMBD[2]] # x,y, where x is the first embedding\n",
    "data2_tst = [TEST_EMBD[1],TEST_EMBD[2]] # x,y, where x is the first embedding\n",
    "data3_tst = [BERT_TEST_embd,TEST_EMBD[2][:len(BERT_TEST_embd)]] # x,y, where x is the first embedding\n",
    "\n",
    "print('model-1 Flair\\'s DocumentPoolEmbeddings\\n')\n",
    "test(model1, data1_tst, criterion, 1, 1, 1)\n",
    "\n",
    "print('model-2 Flair\\'s DocumentLSTMEmbeddings\\n')\n",
    "test(model2, data2_tst, criterion, 1, 1, 1)\n",
    "\n",
    "print('model-3 Google\\'s BERT embeddings\\n')\n",
    "test(model3, data3_tst, criterion, 1, 1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The final scores are as follows:\n",
    "\n",
    "| measure | Flair's LSTM | Flair' Pool | BERT \n",
    "|------|------|------|------|\n",
    "|  precision  | 0.920 | 0.961 | 0.961 |\n",
    "|  recall  | 0.| 0.376 | 0.574 |\n",
    "|  f1-score (macro)  | 0.309 | 0.523 | 0.619 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "The results obtained are comparable with the state-of-the-art results presented in Sun et. al. (2018). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
